{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5069f6",
   "metadata": {},
   "source": [
    "# ChatGPT in My Code\n",
    "- https://www.codingthesmartway.com/how-to-use-chatgpt-with-python/\n",
    "- https://platform.openai.com/docs/guides/chat/introduction\n",
    "- https://medium.com/neo4j/context-aware-knowledge-graph-chatbot-with-gpt-4-and-neo4j-d3a99e8ae21e\n",
    "- https://medium.com/neo4j/creating-a-knowledge-graph-from-video-transcripts-with-gpt-4-52d7c7b9f32c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454cb2e3",
   "metadata": {},
   "source": [
    "## OpenAI API Client Library for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d047fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53765b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f29646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the OpenAI API client\n",
    "openai.api_key = \"<your key here>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf547fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ada: text-embedding-ada-002 (cheapest)\n",
    "# Da Vinci: text-davinci-003 (most expensive)\n",
    "# Comparison here: https://beta.openai.com/docs/models/gpt-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910eb3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model and prompt\n",
    "model_engine = \"text-davinci-003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf971f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Hello, how are you today?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "I need a short video to advertise an introductory elective Data Science course to higher education Software Development students.\n",
    "It involves topics from business intelligence, machine learning, deep learning, artificial neural networks, and graph data science.\n",
    "The participants will be introduced to and learn to implement methods and algorithms for \n",
    "natural language processing and understanding, image recognition, recommendation, fraud detection, \n",
    "missing links prediction, and similar.\n",
    "Important parts of the context will be data visualisation and AI explainability.\n",
    "Please, create an informative and attractive video script that another AI software can 'understand' and implement. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baced03",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "- __temperature__ - controls the level of randomness in the generated text\n",
    "  - higher temperature will result in more varied and potentially less coherent responses\n",
    "  - lower temperature will produce responses that are more predictable and potentially more coherent\n",
    "- __stop__ specifies a string or sequence of strings that, if encountered in the generated text, will cause the model to stop generating further text\n",
    "    - useful for controlling the length of the generated text or for ensuring that the model does not generate inappropriate content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a response\n",
    "completion = openai.Completion.create(\n",
    "    engine=model_engine,\n",
    "    prompt=prompt,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cae65b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = completion.choices[0].text\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cb723",
   "metadata": {},
   "source": [
    "## Other Examples\n",
    "- https://gist.github.com/jayo78/79d8834e6e31bf942c7b604e1611b68d\n",
    "- https://learnprompting.org/docs/applied_prompting/build_chatgpt\n",
    "- https://github.com/openai/openai-quickstart-python/blob/master/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520fcf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"<key here>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63623df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_engine = \"text-babbage-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_prompt = \"\"\"\n",
    "As an advanced chatbot, your primary goal is to assist users to the best of your ability. This may involve answering questions, providing helpful information, or completing tasks based on user input. In order to effectively assist users, it is important to be detailed and thorough in your responses. Use examples and evidence to support your points and justify your recommendations or solutions.\n",
    "<conversation history>\n",
    "User: <user input>\n",
    "Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94827839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(conversation_history, user_input):\n",
    "    prompt = chatbot_prompt.replace(\n",
    "        \"<conversation_history>\", conversation_history).replace(\"<user input>\", user_input)\n",
    "\n",
    "    # Get the response from GPT-3\n",
    "    response = openai.Completion.create(\n",
    "        engine=model_engine, prompt=prompt, max_tokens=512, n=1, stop=None, temperature=0.5)\n",
    "\n",
    "    # Extract the response from the response object\n",
    "    response_text = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "    chatbot_response = response_text.strip()\n",
    "\n",
    "    return chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db11197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    conversation_history = \"\"\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"> \")\n",
    "        if user_input == \"exit\":\n",
    "            break\n",
    "        chatbot_response = get_response(conversation_history, user_input)\n",
    "        print(f\"Chatbot: {chatbot_response}\")\n",
    "        conversation_history += f\"User: {user_input}\\nChatbot: {chatbot_response}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3709cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ec22a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
